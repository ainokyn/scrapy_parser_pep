# Проект парсинга pep с помощью фреймворка Scrapy

## Описание проекта
Данный проект позволяет собирать информацию с статусе, названии и номере документа PEP,
с использованием фреймворка Scrapy.
Для сбора информации был создан «паук» pep, который обращается по адресу http://peps.python.org/.
С данной страницы собирается информация о ссылках на каждый документ PEP, потом происходит переход на
страницу каждого документа, где с помощью css селекторов собирается информация о статусе, названии и номере этого документа. Далее данные передаются в объекты Items. Следующей задачей проекта является вывод двух файлов в формате .csv: первый содержит информацию о  статусе, названии и номере каждого документа, а второй содержит сводную таблицу 
по всем существующим статусам и их количеству, а так же по общему числу документов.
Первый документ будет сформирован через структуру Feeds. Второй документ содержит данные, которые нельзя получить из отдельных Items. Потому использование Feeds не целесообразно. Файл создан через Pipeline. Оба документа сохранены в 
папку results

## Используемые фреймворки

-Scrapy

**Использование**

Необходмо скачать проект, установить виртуальое окружение, активировать ее, установить зависимости.
Далее запустить проект командой `scrapy crawl pep` .

